{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define variables and import the main library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_directory = '/data/BIDS-HPC/private/projects/dmi2'\n",
    "import os, sys\n",
    "links_dir = os.path.join(project_directory, 'data', 'all_gene_expression_files_in_target', 'links')\n",
    "annotation_file = os.path.join(project_directory, 'data', 'gencode.v22.annotation.gtf')\n",
    "sample_sheet_file = os.path.join(project_directory, 'data', 'gdc_sample_sheet.2020-07-02.tsv')\n",
    "metadata_file = os.path.join(project_directory, 'data', 'metadata.cart.2020-07-02.json')\n",
    "if os.path.join(project_directory, 'checkout') not in sys.path:\n",
    "    sys.path.append(os.path.join(project_directory, 'checkout'))\n",
    "import target_class_lib as tc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data downloaded from the GDC Data Portal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_samples, df_counts = tc.load_gdc_data(sample_sheet_file, metadata_file, links_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the FPKM and FPKM-UQ dataframes, and check them with known values if the needed datafiles are present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_fpkm, df_fpkm_uq = tc.get_fpkm(df_counts, annotation_file, df_samples, links_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove from the samples and intensities the samples that correspond to multiple cases (i.e., people)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_samples, indexes_to_keep, _ = tc.drop_multiperson_samples(df_samples)\n",
    "df_counts = df_counts.iloc[indexes_to_keep,:]\n",
    "df_fpkm = df_fpkm.iloc[indexes_to_keep,:]\n",
    "df_fpkm_uq = df_fpkm_uq.iloc[indexes_to_keep,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform exploratory data analysis on the sample labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tc.eda_labels(df_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot histograms of the numerical columns of the samples/labels before and after cutoffs are applied, and print out a summary of what was removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_samples, indexes_to_keep = tc.remove_bad_samples(df_samples)\n",
    "df_counts = df_counts.iloc[indexes_to_keep,:]\n",
    "df_fpkm = df_fpkm.iloc[indexes_to_keep,:]\n",
    "df_fpkm_uq = df_fpkm_uq.iloc[indexes_to_keep,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform exploratory data analysis on the filtered sample labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tc.eda_labels(df_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print some random data for us to spot-check in the files themselves to manually ensure we have a handle on the data arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tc.spot_check_data(df_samples, df_counts, df_fpkm, df_fpkm_uq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the TPM using the counts and gene lengths\n",
    "Note I've confirmed sufficient equality using TPM calculation using FPKM and FPKM-UQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_tpm = tc.get_tpm(df_counts, annotation_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add a labels column based on the project id and sample type columns and show the unique values by decreasing frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_samples['label 1'] = df_samples['project id'] + ', ' + df_samples['sample type']\n",
    "print(df_samples['label 1'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the variance-stabilizing transformation using DESeq2 using this most-detailed set of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X1, y1 = tc.run_vst(df_counts, df_samples['label 1'], project_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and plot PCA and tSNE analyses using the variance-stabilizing-transformed data from DESeq2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform PCA\n",
    "import sklearn.decomposition as sk_decomp\n",
    "pca = sk_decomp.PCA(n_components=10)\n",
    "pca_res = pca.fit_transform(X1.iloc[:,:500])\n",
    "print('Top {} PCA explained variance ratios: {}'.format(10, pca.explained_variance_ratio_))\n",
    "ax = tc.plot_unsupervised_analysis(pca_res, y1)\n",
    "ax.set_title('PCA - variance-stabilizing transformation')\n",
    "\n",
    "# Perform tSNE analysis\n",
    "import sklearn.manifold as sk_manif\n",
    "tsne = sk_manif.TSNE(n_components=2)\n",
    "tsne_res = tsne.fit_transform(X1.iloc[:,:500])\n",
    "ax = tc.plot_unsupervised_analysis(tsne_res, y1)\n",
    "ax.set_title('tSNE - variance-stabilizing transformation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above tSNE plot, we find many interesting things, e.g.:\n",
    "\n",
    "* ALL is spread out in multiple places (all oranges/yellows and early greens), into four main clusters; in particular:\n",
    "  * ALL/P2/PBDC (both /BM and /PB) is located in three of them\n",
    "  * ALL/P2/RBDC (i.e., /BM) is basically isolated to one of them\n",
    "  * ALL/P3 is basically in the fourth cluster\n",
    "* AML has its own single cluster\n",
    "* There are some ALL in an AML cluster and vice versa, though the two corresponding clusters are near each other\n",
    "* CCSK is very tightly clustered\n",
    "* NBL has its own cluster, with one RT instance that may be misclassified\n",
    "* OS is tightly clustered, except for two samples in WT, which may indicate that they are misclassified\n",
    "* Aside from the one possibly misclassified RT, they are all solidly clustered\n",
    "* WT is clustered together\n",
    "* The two normal species are very tightly clustered together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Based on the above observations, make a new set of more sensible labels\n",
    "\n",
    "See comments in each line in the following code block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_samples['label 2'] = df_samples['label 1'] # initialize the new label (2) to the original, most-detailed label (1)\n",
    "df_samples['label 2'][df_samples['label 2'].str.contains('normal', case=False, regex=False)] = 'TARGET-Normal' # set to \"TARGET-Normal\" any label including \"normal\" in its original name\n",
    "df_samples['label 2'] = df_samples['label 2'].str.split(pat=', ', expand=True)[0] # otherwise, just set the label to the project ID (see definition of 'label 1' above)\n",
    "df_samples['label 2'] = df_samples['label 2'].str.split(pat='-', expand=True)[1] # finally, at the same time, both remove \"TARGET-\" from the labels and, for ALL, remove \"-PX\", where X={1,2,3}\n",
    "print(df_samples['label 2'].value_counts()) # print the final labels counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-label the unsupervised plots above, just as a quick check of our new labeling scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the new labels\n",
    "y = df_samples['label 2'].copy()\n",
    "y.index = y.index.str.replace('-', '_')\n",
    "\n",
    "# Redo the plots\n",
    "ax = tc.plot_unsupervised_analysis(pca_res, y)\n",
    "ax.set_title('PCA - variance-stabilizing transformation - with new labels')\n",
    "ax = tc.plot_unsupervised_analysis(tsne_res, y)\n",
    "ax.set_title('tSNE - variance-stabilizing transformation - with new labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that had we not previously plotted the most detailed set of labels, we would have been left forever wondering why the two distinct clusters of AML data.\n",
    "\n",
    "## Now actually run the variance-stabilizing transformation using DESeq2 on the re-labeled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X2, y2 = tc.run_vst(df_counts, df_samples['label 2'], project_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run PCA and tSNE on the new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Perform PCA\n",
    "import sklearn.decomposition as sk_decomp\n",
    "pca = sk_decomp.PCA(n_components=10)\n",
    "pca_res = pca.fit_transform(X2.iloc[:,:500])\n",
    "print('Top {} PCA explained variance ratios: {}'.format(10, pca.explained_variance_ratio_))\n",
    "ax = tc.plot_unsupervised_analysis(pca_res, y2)\n",
    "ax.set_title('PCA - variance-stabilizing transformation')\n",
    "\n",
    "# Perform tSNE analysis\n",
    "import sklearn.manifold as sk_manif\n",
    "tsne = sk_manif.TSNE(n_components=2)\n",
    "tsne_res = tsne.fit_transform(X2.iloc[:,:500])\n",
    "ax = tc.plot_unsupervised_analysis(tsne_res, y2)\n",
    "ax.set_title('tSNE - variance-stabilizing transformation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Old cell\n",
    "\n",
    "## Write annotation and gene counts files (two files total) that are in the same format as the pasilla example\n",
    "\n",
    "# Commenting this out since the sample we're taking is random and I don't want to regenerate it as I didn't save the seed\n",
    "# Don't stress too much about that since this is super easy to regenerate and I should probably implement saving the seed\n",
    "#tc.write_sample_for_deseq2_input(df_samples['label 1'], df_counts, data_directory, 'three_class_sample')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38364bitrenvconda666419ce7e6d428781f855b49005a494",
   "display_name": "Python 3.8.3 64-bit ('r_env': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}