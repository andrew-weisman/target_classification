{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define variables and import the main library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_directory = '/data/BIDS-HPC/private/projects/dmi2'\n",
    "import os, sys\n",
    "links_dir = os.path.join(project_directory, 'data', 'all_gene_expression_files_in_target', 'links')\n",
    "annotation_file = os.path.join(project_directory, 'data', 'gencode.v22.annotation.gtf')\n",
    "sample_sheet_file = os.path.join(project_directory, 'data', 'gdc_sample_sheet.2020-07-02.tsv')\n",
    "metadata_file = os.path.join(project_directory, 'data', 'metadata.cart.2020-07-02.json')\n",
    "if os.path.join(project_directory, 'checkout') not in sys.path:\n",
    "    sys.path.append(os.path.join(project_directory, 'checkout'))\n",
    "import target_class_lib as tc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data downloaded from the GDC Data Portal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_samples, df_counts = tc.load_gdc_data(sample_sheet_file, metadata_file, links_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the FPKM and FPKM-UQ dataframes, and check them with known values if the needed datafiles are present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_fpkm, df_fpkm_uq = tc.get_fpkm(df_counts, annotation_file, df_samples, links_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove from the samples and intensities the samples that correspond to multiple cases (i.e., people)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_samples, indexes_to_keep, _ = tc.drop_multiperson_samples(df_samples)\n",
    "df_counts = df_counts.iloc[indexes_to_keep,:]\n",
    "df_fpkm = df_fpkm.iloc[indexes_to_keep,:]\n",
    "df_fpkm_uq = df_fpkm_uq.iloc[indexes_to_keep,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform exploratory data analysis on the sample labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tc.eda_labels(df_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot histograms of the numerical columns of the samples/labels before and after cutoffs are applied, and print out a summary of what was removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_samples, indexes_to_keep = tc.remove_bad_samples(df_samples)\n",
    "df_counts = df_counts.iloc[indexes_to_keep,:]\n",
    "df_fpkm = df_fpkm.iloc[indexes_to_keep,:]\n",
    "df_fpkm_uq = df_fpkm_uq.iloc[indexes_to_keep,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform exploratory data analysis on the filtered sample labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tc.eda_labels(df_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print some random data for us to spot-check in the files themselves to manually ensure we have a handle on the data arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tc.spot_check_data(df_samples, df_counts, df_fpkm, df_fpkm_uq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the TPM using the counts and gene lengths\n",
    "Note I've confirmed sufficient equality using TPM calculation using FPKM and FPKM-UQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_tpm = tc.get_tpm(df_counts, annotation_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add a labels column based on the project id and sample type columns and show the unique values by decreasing frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_samples['label 1'] = df_samples['project id'] + ', ' + df_samples['sample type']\n",
    "print(df_samples['label 1'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the variance-stabilizing transformation using DESeq2 using this most-detailed set of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X1, y1 = tc.run_vst(df_counts, df_samples['label 1'], project_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and plot PCA and tSNE analyses using the variance-stabilizing-transformed data from DESeq2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Perform PCA\n",
    "import sklearn.decomposition as sk_decomp\n",
    "pca = sk_decomp.PCA(n_components=10)\n",
    "pca_res = pca.fit_transform(X1.iloc[:,:500])\n",
    "#pca_res = pca.fit_transform(X1.iloc[:,:])\n",
    "print('Top {} PCA explained variance ratios: {}'.format(10, pca.explained_variance_ratio_))\n",
    "ax = tc.plot_unsupervised_analysis(pca_res, y1)\n",
    "ax.set_title('PCA - variance-stabilizing transformation')\n",
    "\n",
    "# Perform tSNE analysis\n",
    "import sklearn.manifold as sk_manif\n",
    "tsne = sk_manif.TSNE(n_components=2)\n",
    "tsne_res = tsne.fit_transform(X1.iloc[:,:500])\n",
    "#tsne_res = tsne.fit_transform(X1.iloc[:,:])\n",
    "ax = tc.plot_unsupervised_analysis(tsne_res, y1)\n",
    "ax.set_title('tSNE - variance-stabilizing transformation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above tSNE plot, we find many interesting things, e.g.:\n",
    "\n",
    "* ALL is spread out in multiple places (all oranges/yellows and early greens), into four main clusters; in particular:\n",
    "  * ALL/P2/PBDC (both /BM and /PB) is located in three of them\n",
    "  * ALL/P2/RBDC (i.e., /BM) is basically isolated to one of them\n",
    "  * ALL/P3 is basically in the fourth cluster\n",
    "* AML has its own single cluster\n",
    "* There are some ALL in an AML cluster and vice versa, though the two corresponding clusters are near each other\n",
    "* CCSK is very tightly clustered\n",
    "* NBL has its own cluster, with one RT instance that may be misclassified\n",
    "* OS is tightly clustered, except for two samples in WT, which may indicate that they are misclassified\n",
    "* Aside from the one possibly misclassified RT, they are all solidly clustered\n",
    "* WT is clustered together\n",
    "* The two normal species are very tightly clustered together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Based on the above observations, make a new set of more sensible labels\n",
    "\n",
    "See comments in each line in the following code block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_samples['label 2'] = df_samples['label 1'] # initialize the new label (2) to the original, most-detailed label (1)\n",
    "df_samples['label 2'][df_samples['label 2'].str.contains('normal', case=False, regex=False)] = 'TARGET-Normal' # set to \"TARGET-Normal\" any label including \"normal\" in its original name\n",
    "df_samples['label 2'] = df_samples['label 2'].str.split(pat=', ', expand=True)[0] # otherwise, just set the label to the project ID (see definition of 'label 1' above)\n",
    "df_samples['label 2'] = df_samples['label 2'].str.split(pat='-', expand=True)[1] # finally, at the same time, both remove \"TARGET-\" from the labels and, for ALL, remove \"-PX\", where X={1,2,3}\n",
    "print(df_samples['label 2'].value_counts()) # print the final labels counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-label the unsupervised plots above, just as a quick check of our new labeling scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the new labels\n",
    "y = df_samples['label 2'].copy()\n",
    "y.index = y.index.str.replace('-', '_')\n",
    "y = y.loc[y1.index] # order them the same way as the PCA/tSNE results we already calculated\n",
    "\n",
    "# Redo the plots, with appropriate sorting so that the labels are in alphabetical order\n",
    "sorting_indexes = y.to_numpy().argsort(axis=0)\n",
    "ax = tc.plot_unsupervised_analysis(pca_res[sorting_indexes,:], y.iloc[sorting_indexes])\n",
    "ax.set_title('PCA - variance-stabilizing transformation - with new labels')\n",
    "ax = tc.plot_unsupervised_analysis(tsne_res[sorting_indexes,:], y.iloc[sorting_indexes])\n",
    "ax.set_title('tSNE - variance-stabilizing transformation - with new labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that had we not previously plotted the most detailed set of labels, we would have been left forever wondering why the two distinct clusters of AML data.\n",
    "\n",
    "## Now actually run the variance-stabilizing transformation using DESeq2 on the re-labeled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X2, y2 = tc.run_vst(df_counts, df_samples['label 2'], project_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run PCA and tSNE on the new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Perform PCA\n",
    "import sklearn.decomposition as sk_decomp\n",
    "pca = sk_decomp.PCA(n_components=10)\n",
    "pca_res = pca.fit_transform(X2.iloc[:,:500])\n",
    "print('Top {} PCA explained variance ratios: {}'.format(10, pca.explained_variance_ratio_))\n",
    "ax = tc.plot_unsupervised_analysis(pca_res, y2)\n",
    "ax.set_title('PCA - variance-stabilizing transformation')\n",
    "\n",
    "# Perform tSNE analysis\n",
    "import sklearn.manifold as sk_manif\n",
    "tsne = sk_manif.TSNE(n_components=2)\n",
    "tsne_res = tsne.fit_transform(X2.iloc[:,:500])\n",
    "ax = tc.plot_unsupervised_analysis(tsne_res, y2)\n",
    "ax.set_title('tSNE - variance-stabilizing transformation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a figure helping to explore the extent of sampling each unique label in the dataset (i.e., each group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = tc.explore_sample_size(X2, y2, tsne_res, n_range=range(100,601,100))\n",
    "fig.savefig(os.path.join(project_directory, 'data', 'exploring_sample_size_100_601_100.png'), facecolor='w', dpi=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run some random forest classification models on the data, saving the results and plotting the accuracies of the models on the entire input datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get a reasonable set of sample sizes\n",
    "possible_n = [x for x in range(1,13)] + [x for x in range(15,46,5*2)] + [x for x in range(50,101,10*2)]\n",
    "\n",
    "# Determine the samples of just particular types\n",
    "nbl_or_normal_samples = (y2=='NBL').to_numpy() | (y2=='Normal').to_numpy() # get samples that are NBL or Normal\n",
    "aml_or_normal_samples = (y2=='AML').to_numpy() | (y2=='Normal').to_numpy() # get samples that are AML or Normal\n",
    "\n",
    "# Generate the random forest classification models\n",
    "accuracies, possible_n, rnd_clf_holder = tc.generate_random_forest_models(X2, y2, project_directory, 'all_classes', ntrials=30, possible_n=possible_n) # all data\n",
    "accuracies_nbl, possible_n_nbl, rnd_clf_holder_nbl = tc.generate_random_forest_models(X2.iloc[nbl_or_normal_samples,:], y2.iloc[nbl_or_normal_samples], project_directory, 'nbl_vs_normal', possible_n=possible_n[-10:], ntrials=30) # just NBL/Normal\n",
    "accuracies_aml, possible_n_aml, rnd_clf_holder_aml = tc.generate_random_forest_models(X2.iloc[aml_or_normal_samples,:], y2.iloc[aml_or_normal_samples], project_directory, 'aml_vs_normal', possible_n=possible_n[-10:], ntrials=30) # just AML/Normal\n",
    "\n",
    "# Plot the accuracy vs. sample size for each study type\n",
    "tc.plot_accuracy_vs_sample_size(accuracies, possible_n, 'all classes')\n",
    "tc.plot_accuracy_vs_sample_size(accuracies_nbl, possible_n_nbl, 'NBL vs. normal')\n",
    "tc.plot_accuracy_vs_sample_size(accuracies_aml, possible_n_aml, 'AML vs. normal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine the genes in decreasing order of average feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_genes, _ = tc.calculate_average_feature_importance(X2.columns, rnd_clf_holder)\n",
    "important_genes_nbl, _ = tc.calculate_average_feature_importance(X2.columns, rnd_clf_holder_nbl)\n",
    "important_genes_aml, _ = tc.calculate_average_feature_importance(X2.columns, rnd_clf_holder_aml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print *ROUGHLY* top top-10 differentiating genes in each study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\nAll data\n ENSG00000164853    0.000953\nENSG00000132970    0.000903\nENSG00000137745    0.000896\nENSG00000112559    0.000874\nENSG00000257093    0.000806\nENSG00000139656    0.000805\nENSG00000226519    0.000776\nENSG00000099956    0.000766\nENSG00000150551    0.000752\nENSG00000250208    0.000746\nENSG00000232835    0.000745\nENSG00000125872    0.000734\nENSG00000075891    0.000709\nENSG00000108821    0.000708\nENSG00000130477    0.000707\nENSG00000198363    0.000702\nENSG00000111432    0.000676\nENSG00000157227    0.000661\nENSG00000235180    0.000640\nENSG00000219159    0.000625\nName: score, dtype: float64\n\nNBL vs. normal\n ENSG00000144455    0.000533\nENSG00000175707    0.000533\nENSG00000130962    0.000533\nENSG00000109132    0.000533\nENSG00000132563    0.000500\nENSG00000166986    0.000500\nENSG00000168259    0.000500\nENSG00000227081    0.000500\nENSG00000102471    0.000500\nENSG00000105289    0.000500\nENSG00000172270    0.000500\nENSG00000243547    0.000500\nENSG00000244245    0.000500\nENSG00000261502    0.000467\nENSG00000162390    0.000467\nENSG00000110881    0.000467\nENSG00000236283    0.000467\nENSG00000174460    0.000467\nENSG00000242795    0.000467\nENSG00000185615    0.000467\nName: score, dtype: float64\n\nAML vs. normal\n ENSG00000068001    0.000433\nENSG00000184669    0.000433\nENSG00000087502    0.000433\nENSG00000121440    0.000433\nENSG00000181544    0.000433\nENSG00000058085    0.000433\nENSG00000073350    0.000433\nENSG00000196767    0.000400\nENSG00000188157    0.000400\nENSG00000080293    0.000400\nENSG00000153292    0.000400\nENSG00000267121    0.000400\nENSG00000163638    0.000400\nENSG00000144283    0.000400\nENSG00000088836    0.000400\nENSG00000156284    0.000400\nENSG00000236533    0.000400\nENSG00000260898    0.000400\nENSG00000140939    0.000400\nENSG00000104427    0.000367\nName: score, dtype: float64\n"
    }
   ],
   "source": [
    "print('\\nAll data\\n', important_genes[:20])\n",
    "print('\\nNBL vs. normal\\n', important_genes_nbl[:20])\n",
    "print('\\nAML vs. normal\\n', important_genes_aml[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38364bitrenvconda666419ce7e6d428781f855b49005a494",
   "display_name": "Python 3.8.3 64-bit ('r_env': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}